{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, Ridge\n",
    "fname = 'data.csv'\n",
    "\n",
    "def init_data(fname):\n",
    "    data = pd.read_csv('data.csv')\n",
    "    data['yx_spread'] = data.yprice - data.xprice\n",
    "    data['yx_relation'] = data.yprice / data.xprice\n",
    "    data['xy_relation'] = data.xprice / data.yprice\n",
    "    data['xy_geom'] = np.sqrt(data.xprice * data.yprice)\n",
    "    data['xy_garmonic'] = 2 / (1 / data.xprice + 1 / data.yprice)\n",
    "    \n",
    "#     data.xprice = (data.xprice - data.xprice.min())# / data.xprice.std() \n",
    "#     data.yprice = (data.yprice - data.yprice.min())# / data.yprice.std() \n",
    "    data['timestamp'] = data['timestamp'] // 1000\n",
    "    data['timestamp'] = data['timestamp'].apply(lambda stamp: datetime.fromtimestamp(stamp))\n",
    "    data['timestamp'] = data['timestamp'] - pd.Timedelta(hours=1) # for flexibility\n",
    "    data.index = data['timestamp']\n",
    "    \n",
    "    data['weekday'] = data.timestamp.dt.weekday\n",
    "    data['day'] = (data.timestamp.dt.date - data.timestamp.dt.date.min()).apply(lambda x: int(x.days))\n",
    "    day_close_time = data.day.map(data.groupby('day').timestamp.max())\n",
    "    data['periods_before_closing'] = (day_close_time - data.timestamp).apply(lambda x: x.seconds // 10)\n",
    "    day_open_time = data.day.map(data.groupby('day').timestamp.min())\n",
    "    data['periods_after_opening'] = (data.timestamp - day_open_time).apply(lambda x: x.seconds // 10)\n",
    "#     data.drop('timestamp', 1, inplace=True)\n",
    "    return data\n",
    "    \n",
    "def time_split(data, valid_ratio, test_ratio):\n",
    "    n_valid = max(1, int(data.shape[0] * valid_ratio))\n",
    "    n_test = max(1, int(data.shape[0] * test_ratio))\n",
    "    n_train = data.shape[0] - n_valid - n_test\n",
    "    \n",
    "    train = data.iloc[:n_train].reset_index(drop=True).copy()\n",
    "    valid = data.iloc[n_train:-n_test].reset_index(drop=True).copy()\n",
    "    test = data.iloc[-n_test:].reset_index(drop=True).copy()\n",
    "    merged_test = valid.append(test).reset_index(drop=True)\n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_diffs(df, column, uselags):\n",
    "    new_columns = []\n",
    "    for lag in uselags:\n",
    "        colname = '{}_diff_{}'.format(column, lag)\n",
    "        df.loc[:, colname] = df[column].diff(lag)\n",
    "        new_columns.append(colname)\n",
    "    print(new_columns)\n",
    "    return new_columns\n",
    "\n",
    "def add_shifts(df, column, uselags):\n",
    "    new_columns = []\n",
    "    for lag in uselags:\n",
    "        colname = '{}_lag_{}'.format(column, lag)\n",
    "        df.loc[:, colname] = df[column].shift(lag)\n",
    "        new_columns.append(colname)\n",
    "    print(new_columns)\n",
    "    return new_columns\n",
    "\n",
    "def add_rolling_mean(df, column, windows):\n",
    "    new_columns = []\n",
    "    for window_size in windows:\n",
    "        colname = '{}_ma_{}'.format(column, window_size)\n",
    "        df.loc[:, colname] = df[column].rolling(window=window_size).mean()\n",
    "        new_columns.append(colname)\n",
    "    print(new_columns)\n",
    "    return new_columns\n",
    "\n",
    "def add_curstom_rolling_operation(df, column, agg_function, function_name, windows):\n",
    "    new_columns = []\n",
    "    for window_size in windows:\n",
    "        colname = '{}_{}_{}'.format(column, function_name, window_size)\n",
    "        df.loc[:, colname] = df[column].rolling(window=window_size).agg(agg_function)\n",
    "        new_columns.append(colname)\n",
    "    print(new_columns)\n",
    "    return new_columns  \n",
    "\n",
    "def rsiFunc(prices, n=14):\n",
    "    deltas = np.diff(prices)\n",
    "    seed = deltas[:n+1]\n",
    "    up = seed[seed>=0].sum()/n\n",
    "    down = -seed[seed<0].sum()/n\n",
    "    rs = up/down\n",
    "    rsi = np.zeros_like(prices)\n",
    "    rsi[:n] = 100. - 100./(1.+rs)\n",
    "\n",
    "    for i in range(n, len(prices)):\n",
    "        delta = deltas[i-1] # cause the diff is 1 shorter\n",
    "\n",
    "        if delta>0:\n",
    "            upval = delta\n",
    "            downval = 0.\n",
    "        else:\n",
    "            upval = 0.\n",
    "            downval = -delta\n",
    "\n",
    "        up = (up*(n-1) + upval)/n\n",
    "        down = (down*(n-1) + downval)/n\n",
    "\n",
    "        rs = up/down\n",
    "        rsi[i] = 100. - 100./(1.+rs)\n",
    "\n",
    "    return rsi\n",
    "\n",
    "def add_rsi(df, column, windows):\n",
    "    new_columns = []\n",
    "    for window_size in windows:\n",
    "        colname = '{}_rsi_{}'.format(column, window_size)\n",
    "        df.loc[:, colname] = rsiFunc(df[column].values, window_size)\n",
    "        new_columns.append(colname)\n",
    "    print(new_columns)\n",
    "    return new_columns  \n",
    "\n",
    "def add_ewma(df, column, windows):\n",
    "    new_columns = []\n",
    "    for window_size in windows:\n",
    "        colname = '{}_ewma_{}'.format(column, window_size)\n",
    "        df.loc[:, colname] = pd.Series.ewm(df[column], span=window_size).mean()\n",
    "        new_columns.append(colname)\n",
    "    print(new_columns)\n",
    "    return new_columns \n",
    "\n",
    "def add_time_depended_rolling(df, source_column, windows, agg_fun, agg_repr):\n",
    "    '''\n",
    "        df: source dataframe\n",
    "        source_column: column for building feature\n",
    "        windows: list with periods (1 period = 10 sec)\n",
    "        agg_fun: aggregation function\n",
    "        agg_repr: name of agg function\n",
    "    '''    \n",
    "    new_cols = []\n",
    "    for agg_period in windows:\n",
    "        agg_shifts = range(10, agg_period * 10, 10)\n",
    "        period_repr = '{}s'.format(agg_period * 10)\n",
    "        \n",
    "        agg_helper_df = df[source_column].resample(\n",
    "            period_repr, label='right', closed='right').agg(agg_fun)\n",
    "                                             \n",
    "        for shift in agg_shifts:\n",
    "            agg_helper_df = agg_helper_df.append(df[source_column].resample(\n",
    "                period_repr, label='right', closed='right', base=shift).agg(agg_fun))\n",
    "        colname = '{}_time_{}_{}'.format(source_column, agg_repr, agg_period)\n",
    "        df.loc[:, colname] = agg_helper_df\n",
    "        new_cols.append(colname)\n",
    "    print(new_cols)\n",
    "    return new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hand_feats(df):\n",
    "    close_price_per_day = df.groupby('day').timestamp.max().shift(1).map(\n",
    "        df[['timestamp', 'yprice']].set_index('timestamp').yprice)\n",
    "    df.loc[:, 'ydiff_from_closing'] = (df.day.map(close_price_per_day) - df.yprice).fillna(0)\n",
    "    close_price_per_day = df.groupby('day').timestamp.max().shift(1).map(\n",
    "        df[['timestamp', 'xprice']].set_index('timestamp').xprice)\n",
    "    df.loc[:, 'xdiff_from_closing'] = (df.day.map(close_price_per_day) - df.yprice).fillna(0)\n",
    "    \n",
    "    open_price_per_day = df.groupby('day').timestamp.min().map(\n",
    "        df[['timestamp', 'yprice']].set_index('timestamp').yprice)\n",
    "    df.loc[:, 'ydiff_from_opening'] = (df.day.map(open_price_per_day) - df.yprice)\n",
    "    \n",
    "    open_price_per_day = df.groupby('day').timestamp.min().map(\n",
    "        df[['timestamp', 'xprice']].set_index('timestamp').xprice)\n",
    "    df.loc[:, 'xdiff_from_opening'] = (df.day.map(open_price_per_day) - df.xprice)\n",
    "    new_columns = ['ydiff_from_closing', 'xdiff_from_closing', 'ydiff_from_opening', 'xdiff_from_opening']\n",
    "    print(new_columns)\n",
    "    return new_columns\n",
    "\n",
    "def add_full_history_diff(df, col):\n",
    "    mean = df[col].cumsum() / np.arange(1, df.shape[0] + 1)\n",
    "    new_col = '{}_full_history_diff'.format(col)\n",
    "    df.loc[:, new_col] = df[col] - mean\n",
    "    print(new_col)\n",
    "    return new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_sklearn_model(model, data, selected_cols, valid_ratio, test_ratio, droprows=0, \n",
    "                           verbose=True, only_valid=False):\n",
    "    train, valid, test = time_split(data, valid_ratio, test_ratio)\n",
    "    train.drop(np.arange(droprows), inplace=True)\n",
    "    train.dropna(inplace=True)\n",
    "    if verbose:\n",
    "        print('Data shapes: ', train.shape, valid.shape, test.shape)\n",
    "\n",
    "    metrics_dict = {}\n",
    "    \n",
    "    if valid_ratio!=0:\n",
    "        model.fit(train[selected_cols], train.returns)\n",
    "        y_valid_predicted = model.predict(valid[selected_cols])\n",
    "        y_valid_predicted[valid.periods_before_closing == 0] = 0\n",
    "\n",
    "        metrics_dict['valid_mse'] = mean_squared_error(y_valid_predicted, valid.returns)\n",
    "        metrics_dict['valid_r2'] = r2_score(valid.returns, y_valid_predicted) * 100\n",
    "        if verbose:\n",
    "            print('\\nValid MSE: \\t\\t {:.5}'.format(metrics_dict['valid_mse']))\n",
    "            print('Valid R2 (x100): \\t {:.5}'.format(metrics_dict['valid_r2']))\n",
    "    \n",
    "    if not only_valid:\n",
    "        model.fit(train.append(valid)[selected_cols], train.append(valid).returns)\n",
    "        y_test_predicted = model.predict(test[selected_cols])\n",
    "        y_test_predicted[test.periods_before_closing == 0] = 0\n",
    "\n",
    "        metrics_dict['test_mse'] = mean_squared_error(y_test_predicted, test.returns)\n",
    "        metrics_dict['test_r2'] = r2_score(test.returns, y_test_predicted) * 100\n",
    "        if verbose:\n",
    "            print('\\nTest MSE: \\t\\t {:.5}'.format(metrics_dict['test_mse']))\n",
    "            print('Test R2 (x100): \\t {:.5}'.format(metrics_dict['test_r2']))\n",
    "    \n",
    "    return metrics_dict\n",
    "\n",
    "\n",
    "def greedy_add_del_strategy(model, data, cols, valid_ratio, test_ratio, droprows=0, add_frequency=1):\n",
    "    selected_cols = cols.copy()\n",
    "    removed_cols = []\n",
    "    current_step = 0\n",
    "    \n",
    "    current_score = -float('inf')\n",
    "    \n",
    "    while selected_cols:\n",
    "        current_step += 1\n",
    "        if current_step % add_frequency == 0:\n",
    "            for col in removed_cols:\n",
    "                current_cols = selected_cols + [col]\n",
    "                current_metrics = validate_sklearn_model(\n",
    "                    model, data, current_cols,\n",
    "                    valid_ratio=valid_ratio, test_ratio=test_ratio, droprows=droprows,\n",
    "                    verbose=False, only_valid=True\n",
    "                )\n",
    "                if current_metrics['valid_r2'] > current_score:\n",
    "                    current_score = current_metrics['valid_r2']\n",
    "                    selected_cols.append(col)\n",
    "                    print('added {}: r2: {:.5}'.format(col, current_score))\n",
    "\n",
    "        best_score_by_iter = -float('inf')\n",
    "        worst_col = ''\n",
    "        for col in selected_cols:\n",
    "            current_cols = [c for c in selected_cols if c!=col]\n",
    "            current_metrics = validate_sklearn_model(\n",
    "                model, data, current_cols, \n",
    "                valid_ratio, test_ratio, droprows,\n",
    "                verbose=False, only_valid=True\n",
    "            )\n",
    "\n",
    "            if current_metrics['valid_r2'] > best_score_by_iter:\n",
    "                best_score_by_iter = current_metrics['valid_r2']\n",
    "                worst_col = col\n",
    "        if best_score_by_iter > current_score:\n",
    "            current_score = best_score_by_iter\n",
    "            print('removed {}: r2: {:.5}'.format(worst_col, best_score_by_iter))\n",
    "            selected_cols.remove(worst_col)\n",
    "            removed_cols.append(worst_col)\n",
    "        else:\n",
    "            return selected_cols\n",
    "        \n",
    "def greedy_add_strategy(model, data, base_cols, additional_cols, valid_ratio, test_ratio, droprows=0):\n",
    "    current_score = validate_sklearn_model(\n",
    "        model, data, base_cols,\n",
    "        valid_ratio, test_ratio, droprows,\n",
    "        verbose=False, only_valid=True\n",
    "    )['valid_r2']\n",
    "    is_continue_search = True\n",
    "    while is_continue_search:\n",
    "        is_continue_search = False\n",
    "        for col in additional_cols:\n",
    "            current_cols = base_cols + [col]\n",
    "            current_metrics = validate_sklearn_model(\n",
    "                model, data, current_cols,\n",
    "                valid_ratio, test_ratio, droprows,\n",
    "                verbose=False, only_valid=True\n",
    "            )\n",
    "            if current_metrics['valid_r2'] > current_score:\n",
    "                current_score = current_metrics['valid_r2']\n",
    "                base_cols.append(col)\n",
    "                additional_cols.remove(col)\n",
    "                is_continue_search = True\n",
    "                print('added {}: r2: {:.5}'.format(col, current_score))\n",
    "        \n",
    "    return base_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_agg_periods = [6, 60, 360]\n",
    "oneday_agg_periods = [6, 60, 360, 720, 1410]\n",
    "twoweeks_agg_periods = [6, 60, 360, 720, 1410, 2820, 7050, 14100]\n",
    "\n",
    "month_day_lags = 1410 * np.arange(1, 20)\n",
    "\n",
    "valid_ratio = 0.2\n",
    "test_ratio = 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 6 - 1min\n",
    "- 60 - 10min\n",
    "- 360 - 1hour\n",
    "- 1410 - 1workday (~ 4 hours per day)\n",
    "- 7050 - 1workweek (5 days per week)\n",
    "- 28200 - 1 workmonth (~ 4 weeks per month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heap of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ydiff_from_closing', 'xdiff_from_closing', 'ydiff_from_opening', 'xdiff_from_opening']\n",
      "['xprice_time_mean_6', 'xprice_time_mean_60', 'xprice_time_mean_360']\n",
      "['yprice_time_mean_6', 'yprice_time_mean_60', 'yprice_time_mean_360']\n",
      "xprice_full_history_diff\n",
      "yprice_full_history_diff\n",
      "yx_relation_full_history_diff\n",
      "xy_geom_full_history_diff\n"
     ]
    }
   ],
   "source": [
    "usecols = [\n",
    "    'xprice', 'yprice',\n",
    "    'yx_relation', 'xy_relation',\n",
    "    'yx_spread', 'xy_geom',\n",
    "    'periods_before_closing'\n",
    "]\n",
    "\n",
    "data = init_data(fname)\n",
    "\n",
    "hand_crafted_cols = add_hand_feats(data)\n",
    "usecols.extend(hand_crafted_cols)\n",
    "\n",
    "xcols = add_time_depended_rolling(data, 'xprice', short_agg_periods, np.mean, 'mean')\n",
    "for col in xcols:\n",
    "    data[col] = data.xprice - data[col]\n",
    "usecols.extend(xcols)\n",
    "\n",
    "ycols = add_time_depended_rolling(data, 'yprice', short_agg_periods, np.mean, 'mean')\n",
    "for col in ycols:\n",
    "    data[col] = data.yprice - data[col]\n",
    "usecols.extend(ycols)\n",
    "\n",
    "usecols.append(add_full_history_diff(data, 'xprice'))\n",
    "usecols.append(add_full_history_diff(data, 'yprice'))\n",
    "usecols.append(add_full_history_diff(data, 'yx_relation'))\n",
    "usecols.append(add_full_history_diff(data, 'xy_geom'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed yprice_time_mean_60: r2: 0.84279\n",
      "removed ydiff_from_opening: r2: 0.94374\n",
      "removed xy_geom: r2: 1.0141\n",
      "removed yprice_time_mean_6: r2: 1.0657\n",
      "removed xy_relation: r2: 1.0659\n",
      "Data shapes:  (215660, 27) (68526, 27) (51394, 27)\n",
      "\n",
      "Valid MSE: \t\t 0.019382\n",
      "Valid R2 (x100): \t 1.0659\n",
      "\n",
      "Test MSE: \t\t 0.015794\n",
      "Test R2 (x100): \t 0.76929\n"
     ]
    }
   ],
   "source": [
    "model = Ridge(alpha=10)\n",
    "filtered_cols = greedy_add_del_strategy(model, data, usecols, valid_ratio, test_ratio,\n",
    "                                        droprows=7050, add_frequency=4)\n",
    "validate_sklearn_model(model, data, filtered_cols, valid_ratio, test_ratio, droprows=7050);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yx_spread_rsi_6', 'yx_spread_rsi_60', 'yx_spread_rsi_360', 'yx_spread_rsi_720', 'yx_spread_rsi_1410', 'yx_spread_rsi_2820', 'yx_spread_rsi_7050', 'yx_spread_rsi_14100']\n",
      "added yx_spread_rsi_6: r2: 1.1793\n",
      "added yx_spread_rsi_60: r2: 1.1793\n",
      "Data shapes:  (215660, 35) (68526, 35) (51394, 35)\n",
      "\n",
      "Valid MSE: \t\t 0.01936\n",
      "Valid R2 (x100): \t 1.1793\n",
      "\n",
      "Test MSE: \t\t 0.015835\n",
      "Test R2 (x100): \t 0.51504\n"
     ]
    }
   ],
   "source": [
    "new_cols = add_rsi(data, 'yx_spread', twoweeks_agg_periods)\n",
    "usecols.extend(new_cols)\n",
    "\n",
    "model = Ridge(alpha=10)\n",
    "\n",
    "selected_cols = greedy_add_strategy(model, data, filtered_cols, new_cols,\n",
    "                                    valid_ratio, test_ratio, droprows=7050)\n",
    "validate_sklearn_model(model, data, selected_cols, valid_ratio, test_ratio, droprows=7050);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yx_relation_rsi_6', 'yx_relation_rsi_60', 'yx_relation_rsi_360', 'yx_relation_rsi_720', 'yx_relation_rsi_1410', 'yx_relation_rsi_2820', 'yx_relation_rsi_7050', 'yx_relation_rsi_14100']\n",
      "added yx_relation_rsi_60: r2: 1.2571\n",
      "Data shapes:  (215660, 43) (68526, 43) (51394, 43)\n",
      "\n",
      "Valid MSE: \t\t 0.019345\n",
      "Valid R2 (x100): \t 1.2571\n",
      "\n",
      "Test MSE: \t\t 0.015835\n",
      "Test R2 (x100): \t 0.51512\n"
     ]
    }
   ],
   "source": [
    "new_cols = add_rsi(data, 'yx_relation', twoweeks_agg_periods)\n",
    "usecols.extend(new_cols)\n",
    "\n",
    "model = Ridge(alpha=10)\n",
    "\n",
    "selected_cols = greedy_add_strategy(model, data, selected_cols, new_cols,\n",
    "                                    valid_ratio, test_ratio, droprows=7050)\n",
    "validate_sklearn_model(model, data, selected_cols, valid_ratio, test_ratio, droprows=7050);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xy_relation_rsi_6', 'xy_relation_rsi_60', 'xy_relation_rsi_360', 'xy_relation_rsi_720', 'xy_relation_rsi_1410', 'xy_relation_rsi_2820', 'xy_relation_rsi_7050', 'xy_relation_rsi_14100']\n",
      "added xy_relation_rsi_60: r2: 1.4096\n",
      "Data shapes:  (215660, 51) (68526, 51) (51394, 51)\n",
      "\n",
      "Valid MSE: \t\t 0.019315\n",
      "Valid R2 (x100): \t 1.4096\n",
      "\n",
      "Test MSE: \t\t 0.015836\n",
      "Test R2 (x100): \t 0.50689\n"
     ]
    }
   ],
   "source": [
    "new_cols = add_rsi(data, 'xy_relation', twoweeks_agg_periods)\n",
    "usecols.extend(new_cols)\n",
    "\n",
    "model = Ridge(alpha=10)\n",
    "\n",
    "selected_cols = greedy_add_strategy(model, data, selected_cols, new_cols,\n",
    "                                    valid_ratio, test_ratio, droprows=7050)\n",
    "validate_sklearn_model(model, data, selected_cols, valid_ratio, test_ratio, droprows=7050);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xy_geom_rsi_6', 'xy_geom_rsi_60', 'xy_geom_rsi_360', 'xy_geom_rsi_720', 'xy_geom_rsi_1410', 'xy_geom_rsi_2820', 'xy_geom_rsi_7050', 'xy_geom_rsi_14100']\n",
      "added xy_geom_rsi_360: r2: 1.4761\n",
      "Data shapes:  (215660, 59) (68526, 59) (51394, 59)\n",
      "\n",
      "Valid MSE: \t\t 0.019302\n",
      "Valid R2 (x100): \t 1.4761\n",
      "\n",
      "Test MSE: \t\t 0.015784\n",
      "Test R2 (x100): \t 0.83259\n"
     ]
    }
   ],
   "source": [
    "new_cols = add_rsi(data, 'xy_geom', twoweeks_agg_periods)\n",
    "usecols.extend(new_cols)\n",
    "\n",
    "model = Ridge(alpha=10)\n",
    "\n",
    "selected_cols = greedy_add_strategy(model, data, selected_cols, new_cols,\n",
    "                                    valid_ratio, test_ratio, droprows=7050)\n",
    "validate_sklearn_model(model, data, selected_cols, valid_ratio, test_ratio, droprows=7050);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xy_garmonic_rsi_6', 'xy_garmonic_rsi_60', 'xy_garmonic_rsi_360', 'xy_garmonic_rsi_720', 'xy_garmonic_rsi_1410', 'xy_garmonic_rsi_2820', 'xy_garmonic_rsi_7050', 'xy_garmonic_rsi_14100']\n",
      "added xy_garmonic_rsi_360: r2: 1.6273\n",
      "Data shapes:  (215660, 67) (68526, 67) (51394, 67)\n",
      "\n",
      "Valid MSE: \t\t 0.019272\n",
      "Valid R2 (x100): \t 1.6273\n",
      "\n",
      "Test MSE: \t\t 0.015846\n",
      "Test R2 (x100): \t 0.4434\n"
     ]
    }
   ],
   "source": [
    "new_cols = add_rsi(data, 'xy_garmonic', twoweeks_agg_periods)\n",
    "usecols.extend(new_cols)\n",
    "\n",
    "model = Ridge(alpha=10)\n",
    "\n",
    "selected_cols = greedy_add_strategy(model, data, selected_cols, new_cols,\n",
    "                                    valid_ratio, test_ratio, droprows=7050)\n",
    "validate_sklearn_model(model, data, selected_cols, valid_ratio, test_ratio, droprows=7050);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
