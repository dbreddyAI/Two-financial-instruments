{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, Ridge\n",
    "fname = 'data.csv'\n",
    "\n",
    "def init_data(fname):\n",
    "    data = pd.read_csv('data.csv')\n",
    "    data['yx_spread'] = data.yprice - data.xprice\n",
    "    data['yx_relation'] = data.yprice / data.xprice\n",
    "    data['xy_relation'] = data.xprice / data.yprice\n",
    "    data['xy_geom'] = np.sqrt(data.xprice * data.yprice)\n",
    "    data['xy_garmonic'] = 2 / (1 / data.xprice + 1 / data.yprice)\n",
    "    \n",
    "#     data.xprice = (data.xprice - data.xprice.min())# / data.xprice.std() \n",
    "#     data.yprice = (data.yprice - data.yprice.min())# / data.yprice.std() \n",
    "    data['timestamp'] = data['timestamp'] // 1000\n",
    "    data['timestamp'] = data['timestamp'].apply(lambda stamp: datetime.fromtimestamp(stamp))\n",
    "    data['timestamp'] = data['timestamp'] - pd.Timedelta(hours=1) # for flexibility\n",
    "    data.index = data['timestamp']\n",
    "    \n",
    "    data['weekday'] = data.timestamp.dt.weekday\n",
    "    data['day'] = (data.timestamp.dt.date - data.timestamp.dt.date.min()).apply(lambda x: int(x.days))\n",
    "    day_close_time = data.day.map(data.groupby('day').timestamp.max())\n",
    "    data['periods_before_closing'] = (day_close_time - data.timestamp).apply(lambda x: x.seconds // 10)\n",
    "    day_open_time = data.day.map(data.groupby('day').timestamp.min())\n",
    "    data['periods_after_opening'] = (data.timestamp - day_open_time).apply(lambda x: x.seconds // 10)\n",
    "#     data.drop('timestamp', 1, inplace=True)\n",
    "    return data\n",
    "    \n",
    "def time_split(data, valid_ratio, test_ratio):\n",
    "    n_valid = max(1, int(data.shape[0] * valid_ratio))\n",
    "    n_test = max(1, int(data.shape[0] * test_ratio))\n",
    "    n_train = data.shape[0] - n_valid - n_test\n",
    "    \n",
    "    train = data.iloc[:n_train].reset_index(drop=True).copy()\n",
    "    valid = data.iloc[n_train:-n_test].reset_index(drop=True).copy()\n",
    "    test = data.iloc[-n_test:].reset_index(drop=True).copy()\n",
    "    merged_test = valid.append(test).reset_index(drop=True)\n",
    "    return train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_diffs(df, column, uselags):\n",
    "    new_columns = []\n",
    "    for lag in uselags:\n",
    "        colname = '{}_diff_{}'.format(column, lag)\n",
    "        df.loc[:, colname] = df[column].diff(lag)\n",
    "        new_columns.append(colname)\n",
    "    print(new_columns)\n",
    "    return new_columns\n",
    "\n",
    "def add_shifts(df, column, uselags):\n",
    "    new_columns = []\n",
    "    for lag in uselags:\n",
    "        colname = '{}_lag_{}'.format(column, lag)\n",
    "        df.loc[:, colname] = df[column].shift(lag)\n",
    "        new_columns.append(colname)\n",
    "    print(new_columns)\n",
    "    return new_columns\n",
    "\n",
    "def add_rolling_mean(df, column, windows):\n",
    "    new_columns = []\n",
    "    for window_size in windows:\n",
    "        colname = '{}_ma_{}'.format(column, window_size)\n",
    "        df.loc[:, colname] = df[column].rolling(window=window_size).mean()\n",
    "        new_columns.append(colname)\n",
    "    print(new_columns)\n",
    "    return new_columns\n",
    "\n",
    "def add_curstom_rolling_operation(df, column, agg_function, function_name, windows):\n",
    "    new_columns = []\n",
    "    for window_size in windows:\n",
    "        colname = '{}_{}_{}'.format(column, function_name, window_size)\n",
    "        df.loc[:, colname] = df[column].rolling(window=window_size).agg(agg_function)\n",
    "        new_columns.append(colname)\n",
    "    print(new_columns)\n",
    "    return new_columns  \n",
    "\n",
    "def rsiFunc(prices, n=14):\n",
    "    deltas = np.diff(prices)\n",
    "    seed = deltas[:n+1]\n",
    "    up = seed[seed>=0].sum()/n\n",
    "    down = -seed[seed<0].sum()/n\n",
    "    rs = up/down\n",
    "    rsi = np.zeros_like(prices)\n",
    "    rsi[:n] = 100. - 100./(1.+rs)\n",
    "\n",
    "    for i in range(n, len(prices)):\n",
    "        delta = deltas[i-1] # cause the diff is 1 shorter\n",
    "\n",
    "        if delta>0:\n",
    "            upval = delta\n",
    "            downval = 0.\n",
    "        else:\n",
    "            upval = 0.\n",
    "            downval = -delta\n",
    "\n",
    "        up = (up*(n-1) + upval)/n\n",
    "        down = (down*(n-1) + downval)/n\n",
    "\n",
    "        rs = up/down\n",
    "        rsi[i] = 100. - 100./(1.+rs)\n",
    "\n",
    "    return rsi\n",
    "\n",
    "def add_rsi(df, column, windows):\n",
    "    new_columns = []\n",
    "    for window_size in windows:\n",
    "        colname = '{}_rsi_{}'.format(column, window_size)\n",
    "        df.loc[:, colname] = rsiFunc(df[column].values, window_size)\n",
    "        new_columns.append(colname)\n",
    "    print(new_columns)\n",
    "    return new_columns  \n",
    "\n",
    "def add_ewma(df, column, windows):\n",
    "    new_columns = []\n",
    "    for window_size in windows:\n",
    "        colname = '{}_ewma_{}'.format(column, window_size)\n",
    "        df.loc[:, colname] = pd.Series.ewm(df[column], span=window_size).mean()\n",
    "        new_columns.append(colname)\n",
    "    print(new_columns)\n",
    "    return new_columns \n",
    "\n",
    "def add_time_depended_rolling(df, source_column, agg_periods_per_seconds, agg_fun, agg_repr):\n",
    "    '''\n",
    "        df: source dataframe\n",
    "        source_column: column for building feature\n",
    "        agg_periods_per_seconds: list with periods in seconds\n",
    "        agg_fun: aggregation function\n",
    "        agg_repr: name of agg function\n",
    "    '''\n",
    "    is_allowed_arguments = sum(map(lambda x: x % 10, agg_periods_per_seconds)) == 0\n",
    "    assert is_allowed_arguments, 'agg_periods_per_seconds divided by 10'\n",
    "    \n",
    "    new_cols = []\n",
    "    for agg_period in agg_periods_per_seconds:\n",
    "        agg_shifts = range(10, agg_period, 10)\n",
    "        period_repr = '{}s'.format(agg_period)\n",
    "        \n",
    "        agg_helper_df = df[source_column].resample(\n",
    "            period_repr, label='right', closed='right').agg(agg_fun)\n",
    "                                             \n",
    "        for shift in agg_shifts:\n",
    "            agg_helper_df = agg_helper_df.append(df[source_column].resample(\n",
    "                period_repr, label='right', closed='right', base=shift).agg(agg_fun))\n",
    "        colname = '{}_time_{}_{}'.format(source_column, agg_repr, agg_period)\n",
    "        df.loc[:, colname] = agg_helper_df\n",
    "        new_cols.append(colname)\n",
    "    print(new_cols)\n",
    "    return new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hand_feats(df):\n",
    "    close_price_per_day = df.groupby('day').timestamp.max().shift(1).map(\n",
    "        df[['timestamp', 'yprice']].set_index('timestamp').yprice)\n",
    "    df.loc[:, 'ydiff_from_closing'] = (df.day.map(close_price_per_day) - df.yprice).fillna(0)\n",
    "    close_price_per_day = df.groupby('day').timestamp.max().shift(1).map(\n",
    "        df[['timestamp', 'xprice']].set_index('timestamp').xprice)\n",
    "    df.loc[:, 'xdiff_from_closing'] = (df.day.map(close_price_per_day) - df.yprice).fillna(0)\n",
    "    \n",
    "    open_price_per_day = df.groupby('day').timestamp.min().map(\n",
    "        df[['timestamp', 'yprice']].set_index('timestamp').yprice)\n",
    "    df.loc[:, 'ydiff_from_opening'] = (df.day.map(open_price_per_day) - df.yprice)\n",
    "    \n",
    "    open_price_per_day = df.groupby('day').timestamp.min().map(\n",
    "        df[['timestamp', 'xprice']].set_index('timestamp').xprice)\n",
    "    df.loc[:, 'xdiff_from_opening'] = (df.day.map(open_price_per_day) - df.xprice)\n",
    "    new_columns = ['ydiff_from_closing', 'xdiff_from_closing', 'ydiff_from_opening', 'xdiff_from_opening']\n",
    "    print(new_columns)\n",
    "    return new_columns\n",
    "\n",
    "def add_full_history_diff(df, col):\n",
    "    mean = df[col].cumsum() / np.arange(1, df.shape[0] + 1)\n",
    "    new_col = '{}_full_history_diff'.format(col)\n",
    "    df.loc[:, new_col] = df[col] - mean\n",
    "    print(new_col)\n",
    "    return new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_sklearn_model(model, data, selected_cols, valid_rate, test_rate, droprows=0, verbose=True):\n",
    "    train, valid, test = time_split(data, valid_rate, test_rate)\n",
    "    train.drop(np.arange(droprows), inplace=True)\n",
    "    train.dropna(inplace=True)\n",
    "    if verbose:\n",
    "        print('Data shapes: ', train.shape, valid.shape, test.shape)\n",
    "\n",
    "    metrics_dict = {}\n",
    "    \n",
    "    if valid_rate!=0:\n",
    "        model.fit(train[selected_cols], train.returns)\n",
    "        y_valid_predicted = model.predict(valid[selected_cols])\n",
    "        y_valid_predicted[valid.periods_before_closing == 0] = 0\n",
    "\n",
    "        metrics_dict['valid_mse'] = mean_squared_error(y_valid_predicted, valid.returns)\n",
    "        metrics_dict['valid_r2'] = r2_score(valid.returns, y_valid_predicted) * 100\n",
    "        if verbose:\n",
    "            print('\\nValid MSE: \\t\\t {:.5}'.format(metrics_dict['valid_mse']))\n",
    "            print('Valid R2 (x100): \\t {:.5}'.format(metrics_dict['valid_r2']))\n",
    "    \n",
    "    if test_rate!=0:\n",
    "        model.fit(train.append(valid)[selected_cols], train.append(valid).returns)\n",
    "        y_test_predicted = model.predict(test[selected_cols])\n",
    "        y_test_predicted[test.periods_before_closing == 0] = 0\n",
    "\n",
    "        metrics_dict['test_mse'] = mean_squared_error(y_test_predicted, test.returns)\n",
    "        metrics_dict['test_r2'] = r2_score(test.returns, y_test_predicted) * 100\n",
    "        if verbose:\n",
    "            print('\\nTest MSE: \\t\\t {:.5}'.format(metrics_dict['test_mse']))\n",
    "            print('Test R2 (x100): \\t {:.5}'.format(metrics_dict['test_r2']))\n",
    "    \n",
    "    return metrics_dict\n",
    "\n",
    "\n",
    "def greedy_add_del_strategy(model, data, cols, test_rate, droprows=600, add_frequency=3):\n",
    "    selected_cols = cols.copy()\n",
    "    removed_cols = []\n",
    "    current_step = 0\n",
    "    \n",
    "    current_score = 0\n",
    "    \n",
    "    while selected_cols:\n",
    "        current_step += 1\n",
    "        if current_step % add_frequency == 0:\n",
    "            for col in removed_cols:\n",
    "                current_cols = selected_cols + [col]\n",
    "                current_metrics = validate_sklearn_model(\n",
    "                    model, data, current_cols,\n",
    "                    valid_rate=0, test_rate=test_rate, droprows=600,\n",
    "                    verbose=False\n",
    "                )\n",
    "                if current_metrics['test_r2'] > current_score:\n",
    "                    current_score = current_metrics['test_r2']\n",
    "                    selected_cols.append(col)\n",
    "                    print('added {}: r2: {:.5}'.format(col, current_score))\n",
    "\n",
    "        best_score_by_iter = 0\n",
    "        worst_col = ''\n",
    "        for col in selected_cols:\n",
    "            current_cols = [c for c in selected_cols if c!=col]\n",
    "            current_metrics = validate_sklearn_model(\n",
    "                model, data, current_cols, \n",
    "                valid_rate=0, test_rate=test_rate, droprows=600,\n",
    "                verbose=False\n",
    "            )\n",
    "            if current_metrics['test_r2'] > best_score_by_iter:\n",
    "                best_score_by_iter = current_metrics['test_r2']\n",
    "                worst_col = col\n",
    "        if best_score_by_iter > current_score:\n",
    "            current_score = best_score_by_iter\n",
    "            print('removed {}: r2: {:.5}'.format(worst_col, best_score_by_iter))\n",
    "            selected_cols.remove(worst_col)\n",
    "            removed_cols.append(worst_col)\n",
    "        else:\n",
    "            return selected_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_agg_periods = [60, 600, 3600]\n",
    "oneday_agg_periods = [60, 600, 3600, 7200, 14100]\n",
    "\n",
    "standart_calendar_lags = [6, 60, 360, 1410, 7050, 14100, 28200, 42300]\n",
    "qazy_calendar_lags = [6, 60, 360, 720, 1410, 2820, 7050, 14100, 28200, 42300]\n",
    "day_lags = 1410 * np.arange(1, 75)\n",
    "valid_ratio = 0\n",
    "test_ratio = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trivial solutuin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:  (274103, 17) (1, 17) (68526, 17)\n",
      "Zero Prediction MSE: \t 0.018675\n",
      "Mean Prediction MSE: \t 0.018637\n",
      "Mean Prediction R2: \t 0.0\n"
     ]
    }
   ],
   "source": [
    "train, valid, test = time_split(data, valid_ratio, test_ratio)\n",
    "train.dropna(inplace=True)\n",
    "\n",
    "trivial_solution = np.ones_like(test.returns.values) * test.returns.mean()\n",
    "print('Zero Prediction MSE: \\t {:.5}'.format(np.mean(np.square(test.returns.values))))\n",
    "print('Mean Prediction MSE: \\t {:.5}'.format(mean_squared_error(test.returns, trivial_solution)))\n",
    "print('Mean Prediction R2: \\t {:.5}'.format(r2_score(test.returns, trivial_solution)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:  (205578, 13) (68526, 13) (68526, 13)\n",
      "\n",
      "Valid MSE: \t\t 0.01894\n",
      "Valid R2 (x100): \t -2.073\n",
      "\n",
      "Test MSE: \t\t 0.018595\n",
      "Test R2 (x100): \t 0.22516\n"
     ]
    }
   ],
   "source": [
    "data = init_data(fname)\n",
    "selected_cols = ['xprice', 'yprice']\n",
    "\n",
    "model = Ridge()\n",
    "model.fit(train[usecols], train.returns)\n",
    "validate_sklearn_model(model, data, selected_cols, valid_rate=0.2, test_rate=0.2, droprows=600);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ydiff_from_closing', 'xdiff_from_closing', 'ydiff_from_opening', 'xdiff_from_opening']\n",
      "Data shapes:  (274103, 17) (1, 17) (68526, 17)\n"
     ]
    }
   ],
   "source": [
    "usecols = [\n",
    "    'xprice', 'yprice',\n",
    "    'yx_relation', 'xy_relation',\n",
    "    'yx_spread', 'xy_geom', 'xy_garmonic',\n",
    "    'periods_before_closing'\n",
    "]\n",
    "\n",
    "data = init_data(fname)\n",
    "hand_crafted_cols = add_hand_feats(data)\n",
    "usecols.extend(hand_crafted_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:  (205578, 17) (68526, 17) (68526, 17)\n",
      "\n",
      "Valid MSE: \t\t 0.018874\n",
      "Valid R2 (x100): \t -1.7135\n",
      "\n",
      "Test MSE: \t\t 0.018532\n",
      "Test R2 (x100): \t 0.56464\n"
     ]
    }
   ],
   "source": [
    "removing_cols = [\n",
    "    'periods_before_closing',\n",
    "    'xy_relation',\n",
    "    'yx_relation',\n",
    "    'xy_geom',\n",
    "    'xy_garmonic'\n",
    "]\n",
    "selected_cols = [col for col in usecols if col not in removing_cols]\n",
    "\n",
    "model = Ridge(alpha=1)\n",
    "validate_sklearn_model(model, data, selected_cols, valid_rate=0.2, test_rate=0.2, droprows=600);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:  (205578, 17) (68526, 17) (68526, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sneddy/.local/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2533.1061725847194, tolerance: 0.7257524017355669\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valid MSE: \t\t 0.018872\n",
      "Valid R2 (x100): \t -1.7057\n",
      "\n",
      "Test MSE: \t\t 0.018534\n",
      "Test R2 (x100): \t 0.55649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sneddy/.local/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3662.146866448185, tolerance: 0.8530647321574261\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "removing_cols = [\n",
    "    'periods_before_closing',\n",
    "#     'xy_relation',\n",
    "    'yx_relation',\n",
    "#     'xy_geom',\n",
    "#     'xy_garmonic'\n",
    "]\n",
    "selected_cols = [col for col in usecols if col not in removing_cols]\n",
    "\n",
    "\n",
    "model = ElasticNet(alpha=0.0001, l1_ratio=0.1, max_iter=1000)\n",
    "validate_sklearn_model(model, data, selected_cols, valid_rate=0.2, test_rate=0.2, droprows=600);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agg v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 6 - 1min\n",
    "- 60 - 10min\n",
    "- 360 - 1hour\n",
    "- 1410 - 1workday (~ 4 hours per day)\n",
    "- 7050 - 1workweek (5 days per week)\n",
    "- 28200 - 1 workmonth (~ 4 weeks per month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ydiff_from_closing', 'xdiff_from_closing', 'ydiff_from_opening', 'xdiff_from_opening']\n",
      "['xprice_time_mean_60', 'xprice_time_mean_600', 'xprice_time_mean_3600']\n",
      "['yprice_time_mean_60', 'yprice_time_mean_600', 'yprice_time_mean_3600']\n"
     ]
    }
   ],
   "source": [
    "usecols = [\n",
    "    'xprice', 'yprice',\n",
    "    'yx_relation', 'xy_relation',\n",
    "    'yx_spread', 'xy_geom', 'xy_garmonic',\n",
    "    'periods_before_closing'\n",
    "]\n",
    "\n",
    "data = init_data(fname)\n",
    "\n",
    "hand_crafted_cols = add_hand_feats(data)\n",
    "usecols.extend(hand_crafted_cols)\n",
    "\n",
    "xcols = add_time_depended_rolling(data, 'xprice', short_agg_periods, np.mean, 'mean')\n",
    "usecols.extend(xcols)\n",
    "\n",
    "ycols = add_time_depended_rolling(data, 'yprice', short_agg_periods, np.mean, 'mean')\n",
    "usecols.extend(ycols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:  (205578, 23) (68526, 23) (68526, 23)\n",
      "\n",
      "Valid MSE: \t\t 0.018847\n",
      "Valid R2 (x100): \t -1.5725\n",
      "\n",
      "Test MSE: \t\t 0.018352\n",
      "Test R2 (x100): \t 1.5328\n"
     ]
    }
   ],
   "source": [
    "removing_cols = [\n",
    "    'periods_before_closing',\n",
    "    'xy_relation',\n",
    "    'yx_relation',\n",
    "    'xy_geom',\n",
    "    'xy_garmonic'\n",
    "]\n",
    "selected_cols = [col for col in usecols if col not in removing_cols]\n",
    "\n",
    "model = Ridge(alpha=10)\n",
    "validate_sklearn_model(model, data, selected_cols, valid_rate=0.2, test_rate=0.2, droprows=600);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:  (205578, 23) (68526, 23) (68526, 23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sneddy/.local/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3435.4159233800874, tolerance: 0.7257524017355669\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valid MSE: \t\t 0.018818\n",
      "Valid R2 (x100): \t -1.4125\n",
      "\n",
      "Test MSE: \t\t 0.018436\n",
      "Test R2 (x100): \t 1.081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sneddy/.local/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4002.753452957608, tolerance: 0.8530647321574261\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "removing_cols = [\n",
    "    'periods_before_closing',\n",
    "    'xy_relation',\n",
    "#     'yx_relation',\n",
    "#     'xy_geom',\n",
    "#     'xy_garmonic'\n",
    "]\n",
    "selected_cols = [col for col in usecols if col not in removing_cols]\n",
    "\n",
    "\n",
    "model = ElasticNet(alpha=0.0001, l1_ratio=0.2, max_iter=1000)\n",
    "validate_sklearn_model(model, data, selected_cols, valid_rate=0.2, test_rate=0.2, droprows=600);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full History Diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ydiff_from_closing', 'xdiff_from_closing', 'ydiff_from_opening', 'xdiff_from_opening']\n",
      "['xprice_time_mean_60', 'xprice_time_mean_600', 'xprice_time_mean_3600']\n",
      "['yprice_time_mean_60', 'yprice_time_mean_600', 'yprice_time_mean_3600']\n",
      "xprice_full_history_diff\n",
      "yprice_full_history_diff\n",
      "yx_relation_full_history_diff\n",
      "xy_geom_full_history_diff\n"
     ]
    }
   ],
   "source": [
    "usecols = [\n",
    "    'xprice', 'yprice',\n",
    "    'yx_relation', 'xy_relation',\n",
    "    'yx_spread', 'xy_geom', 'xy_garmonic',\n",
    "    'periods_before_closing'\n",
    "]\n",
    "\n",
    "data = init_data(fname)\n",
    "\n",
    "hand_crafted_cols = add_hand_feats(data)\n",
    "usecols.extend(hand_crafted_cols)\n",
    "\n",
    "xcols = add_time_depended_rolling(data, 'xprice', short_agg_periods, np.mean, 'mean')\n",
    "for col in xcols:\n",
    "    data[col] = data.xprice - data[col]\n",
    "usecols.extend(xcols)\n",
    "\n",
    "ycols = add_time_depended_rolling(data, 'yprice', short_agg_periods, np.mean, 'mean')\n",
    "for col in ycols:\n",
    "    data[col] = data.yprice - data[col]\n",
    "usecols.extend(ycols)\n",
    "\n",
    "usecols.append(add_full_history_diff(data, 'xprice'))\n",
    "usecols.append(add_full_history_diff(data, 'yprice'))\n",
    "usecols.append(add_full_history_diff(data, 'yx_relation'))\n",
    "usecols.append(add_full_history_diff(data, 'xy_geom'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:  (204978, 27) (68526, 27) (68526, 27)\n",
      "\n",
      "Valid MSE: \t\t 0.018884\n",
      "Valid R2 (x100): \t -1.7677\n",
      "\n",
      "Test MSE: \t\t 0.018332\n",
      "Test R2 (x100): \t 1.6395\n"
     ]
    }
   ],
   "source": [
    "removing_cols = [\n",
    "    'xprice',\n",
    "#     'yprice',\n",
    "    'periods_before_closing',\n",
    "#     'yx_spread',\n",
    "    'xy_relation',\n",
    "    'yx_relation',\n",
    "    'xy_geom',\n",
    "    'xy_garmonic',\n",
    "    'yx_relation_full_history_diff',\n",
    "    'xy_geom_full_history_diff',\n",
    "    'xprice_full_history_diff',\n",
    "#     'yprice_full_history_diff',\n",
    "]\n",
    "\n",
    "selected_cols = [col for col in usecols if col not in removing_cols]\n",
    "model = Ridge(alpha=10)\n",
    "validate_sklearn_model(model, data, selected_cols, valid_rate=0.2, test_rate=0.2, droprows=600);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removed xdiff_from_opening: r2: 1.0394\n",
      "removed xdiff_from_closing: r2: 1.2817\n",
      "removed xy_garmonic: r2: 1.4445\n",
      "removed xy_geom: r2: 1.5929\n",
      "removed xprice_full_history_diff: r2: 1.8184\n",
      "removed xy_geom_full_history_diff: r2: 1.8573\n",
      "removed yprice_time_mean_60: r2: 1.875\n",
      "removed periods_before_closing: r2: 1.8903\n",
      "removed yx_relation_full_history_diff: r2: 1.8976\n",
      "removed xy_relation: r2: 1.8997\n",
      "removed yx_relation: r2: 1.9\n",
      "removed yprice: r2: 1.9\n",
      "Data shapes:  (204978, 27) (68526, 27) (68526, 27)\n",
      "\n",
      "Valid MSE: \t\t 0.018874\n",
      "Valid R2 (x100): \t -1.7182\n",
      "\n",
      "Test MSE: \t\t 0.018283\n",
      "Test R2 (x100): \t 1.9\n"
     ]
    }
   ],
   "source": [
    "model = Ridge(alpha=10)\n",
    "filtered_cols = greedy_add_del_strategy(model, data, usecols, test_rate=0.2, droprows=600)\n",
    "validate_sklearn_model(model, data, filtered_cols, valid_rate=0.2, test_rate=0.2, droprows=600);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shapes:  (205578, 27) (68526, 27) (68526, 27)\n",
      "\n",
      "Valid MSE: \t\t 0.018882\n",
      "Valid R2 (x100): \t -1.7585\n",
      "\n",
      "Test MSE: \t\t 0.018379\n",
      "Test R2 (x100): \t 1.3854\n"
     ]
    }
   ],
   "source": [
    "removing_cols = [\n",
    "    'xprice',\n",
    "#     'yprice'\n",
    "    'periods_before_closing',\n",
    "    'yx_spread',\n",
    "#     'xy_relation',\n",
    "#     'yx_relation',\n",
    "    'xy_geom',\n",
    "    'xy_garmonic',\n",
    "#     'yx_relation_full_history_diff',\n",
    "#     'xy_geom_full_history_diff',\n",
    "#     'xprice_full_history_diff',\n",
    "#     'yprice_full_history_diff',\n",
    "]\n",
    "\n",
    "selected_cols = [col for col in usecols if col not in removing_cols]\n",
    "\n",
    "\n",
    "model = ElasticNet(alpha=0.001, l1_ratio=0.1, max_iter=2000)\n",
    "validate_sklearn_model(model, data, selected_cols, valid_rate=0.2, test_rate=0.2, droprows=600);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heap of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
